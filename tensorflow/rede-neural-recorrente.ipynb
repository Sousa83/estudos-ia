{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 2.4.1\n",
      "np: 1.19.5\n"
     ]
    }
   ],
   "source": [
    "#tamnaho máximo de cada review, 100 caracteres\n",
    "maxLenght = 100\n",
    "\n",
    "#carregamento da base de dados\n",
    "print(f'tf: {tf.__version__}\\nnp: {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando base \n",
    "(xTrain, yTrain), (xTest, yTest) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25 mil textos\n",
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cada número está associado à uma palavra, isso para a base toda. \n",
    "#Ela está toda processada, feito o mapeamento de número para palavra\n",
    "xTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiro review \n",
    "xTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classificações, zero e um (positivo e negativo respetivamente)\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo inteiros para palavras novamente com a finalidade de ver as reviews\n",
    "#Um dicionário na qual tem, para cada palabra, um número associado\n",
    "wordIndex = imdb.get_word_index()\n",
    "\n",
    "#Atribuindo um novo dicionário\n",
    "wordIndex = {\n",
    "    k: (v + 3)\n",
    "    \n",
    "    for k,v in wordIndex.items()\n",
    "}\n",
    "\n",
    "wordIndex[\"<PAD>\"] = 0\n",
    "wordIndex[\"<START>\"] = 1\n",
    "wordIndex[\"<UNK>\"] = 2 \n",
    "wordIndex[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverseWordIndex = dict([(value, key) for (key, value) in  wordIndex.items()])\n",
    "\n",
    "def decodeReview(text):\n",
    "    return ' '.join([reverseWordIndex.get(i, '?') for i in text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> worst mistake of my life br br i picked this movie up at target for 5 because i figured hey it's sandler i can get some cheap laughs i was wrong completely wrong mid way through the film all three of my friends were asleep and i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon bashing my head in i stuck that damn movie in the <UNK> and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodeReview(xTrain[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cada review precisa estar com o mesmo tamanho, note que abaixo eles não estão \n",
    "print(f'length of rev 0: {len(xTrain[0])} length of rev 1: {len(xTrain[1])}')\n",
    "\n",
    "#normalizo cada review fazendo um padding (preenchimento) para que todas tenham o mesmo tamanho\n",
    "xTrain = tf.keras.preprocessing.sequence.pad_sequences(xTrain, maxlen=maxLenght)\n",
    "xTest = tf.keras.preprocessing.sequence.pad_sequences(xTest, maxlen=maxLenght)\n",
    "\n",
    "#Agora estão com o mesmo tamanho\n",
    "print(f'length of rev 0: {len(xTrain[0])} length of rev 1: {len(xTrain[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
