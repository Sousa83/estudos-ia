{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamento e processamento da base\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: 2.4.1\n",
      "np: 1.19.5\n"
     ]
    }
   ],
   "source": [
    "#tamnaho máximo de cada review, 100 caracteres\n",
    "maxLenght = 100\n",
    "\n",
    "#carregamento da base de dados\n",
    "print(f'tf: {tf.__version__}\\nnp: {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando base \n",
    "(xTrain, yTrain), (xTest, yTest) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#25 mil textos\n",
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cada número está associado à uma palavra, isso para a base toda. \n",
    "#Ela está toda processada, feito o mapeamento de número para palavra\n",
    "xTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiro review \n",
    "xTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classificações, zero e um (positivo e negativo respetivamente)\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo inteiros para palavras novamente com a finalidade de ver as reviews\n",
    "#Um dicionário na qual tem, para cada palabra, um número associado\n",
    "wordIndex = imdb.get_word_index()\n",
    "\n",
    "#Atribuindo um novo dicionário\n",
    "wordIndex = {\n",
    "    k: (v + 3)\n",
    "    \n",
    "    for k,v in wordIndex.items()\n",
    "}\n",
    "\n",
    "wordIndex[\"<PAD>\"] = 0\n",
    "wordIndex[\"<START>\"] = 1\n",
    "wordIndex[\"<UNK>\"] = 2 \n",
    "wordIndex[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverseWordIndex = dict([(value, key) for (key, value) in  wordIndex.items()])\n",
    "\n",
    "def decodeReview(text):\n",
    "    return ' '.join([reverseWordIndex.get(i, '?') for i in text])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> worst mistake of my life br br i picked this movie up at target for 5 because i figured hey it's sandler i can get some cheap laughs i was wrong completely wrong mid way through the film all three of my friends were asleep and i was still suffering worst plot worst script worst movie i have ever seen i wanted to hit my head up against a wall for an hour then i'd stop and you know why because it felt damn good upon bashing my head in i stuck that damn movie in the <UNK> and watched it burn and that felt better than anything else i've ever done it took american psycho army of darkness and kill bill just to get over that crap i hate you sandler for actually going through with this and ruining a whole day of my life\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decodeReview(xTrain[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of rev 0: 218 length of rev 1: 189\n",
      "length of rev 0: 100 length of rev 1: 100\n"
     ]
    }
   ],
   "source": [
    "#cada review precisa estar com o mesmo tamanho, note que abaixo eles não estão \n",
    "print(f'length of rev 0: {len(xTrain[0])} length of rev 1: {len(xTrain[1])}')\n",
    "\n",
    "#normalizo cada review fazendo um padding (preenchimento) para que todas tenham o mesmo tamanho\n",
    "xTrain = tf.keras.preprocessing.sequence.pad_sequences(xTrain, maxlen=maxLenght)\n",
    "xTest = tf.keras.preprocessing.sequence.pad_sequences(xTest, maxlen=maxLenght)\n",
    "\n",
    "#Agora estão com o mesmo tamanho\n",
    "print(f'length of rev 0: {len(xTrain[0])} length of rev 1: {len(xTrain[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estruturando a RNN\n",
    "\n",
    "model = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adicionando camada de embedding: responsável por fazer uma matriz de números com as palavras\n",
    "#teremos na matriz 10k de linhas (cada uma é uma palavra) e 128 colunas\n",
    "#O modelo terá 100 entradas\n",
    "model.add(tf.keras.layers.Embedding(input_dim=10000, output_dim=128, input_shape=(xTrain.shape[1], )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando a camada LSTM com 128 células de memória\n",
    "model.add(tf.keras.layers.LSTM(units=128, activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando a camada de saida\n",
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilando e treinando o modelo\n",
    "\n",
    "#O modelo terá o otimizador \"rmsprop\" que é mais indicado em casos de RNN\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 128)          1280000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,411,713\n",
      "Trainable params: 1,411,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "193/193 [==============================] - 72s 372ms/step - loss: 0.2257 - accuracy: 0.9118\n",
      "Epoch 2/3\n",
      "193/193 [==============================] - 71s 367ms/step - loss: 0.1954 - accuracy: 0.9264\n",
      "Epoch 3/3\n",
      "193/193 [==============================] - 71s 370ms/step - loss: 0.1660 - accuracy: 0.9384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25b1d9c3ca0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xTrain, yTrain, epochs=3, batch_size=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 32s - loss: 0.5543 - accuracy: 0.8294\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(xTest,  yTest, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
