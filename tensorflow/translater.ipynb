{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Configuração"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "\r\n",
    "# Tipagem\r\n",
    "import typing \r\n",
    "from typing import Any, Tuple\r\n",
    "\r\n",
    "# Auxiliares\r\n",
    "import pathlib\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.ticker as ticker\r\n",
    "\r\n",
    "# Core\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_text as tf_text\r\n",
    "from tensorflow.keras.layers.experimental import preprocessing\r\n",
    "\r\n",
    "# Classe auxliar\r\n",
    "class ShapeChecker():\r\n",
    "  def __init__(self):\r\n",
    "    # Keep a cache of every axis-name seen\r\n",
    "    self.shapes = {}\r\n",
    "\r\n",
    "  def __call__(self, tensor, names, broadcast=False):\r\n",
    "    if not tf.executing_eagerly():\r\n",
    "      return\r\n",
    "\r\n",
    "    if isinstance(names, str):\r\n",
    "      names = (names,)\r\n",
    "\r\n",
    "    shape = tf.shape(tensor)\r\n",
    "    rank = tf.rank(tensor)\r\n",
    "\r\n",
    "    if rank != len(names):\r\n",
    "      raise ValueError(f'Rank mismatch:\\n'\r\n",
    "                       f'    found {rank}: {shape.numpy()}\\n'\r\n",
    "                       f'    expected {len(names)}: {names}\\n')\r\n",
    "\r\n",
    "    for i, name in enumerate(names):\r\n",
    "      if isinstance(name, int):\r\n",
    "        old_dim = name\r\n",
    "      else:\r\n",
    "        old_dim = self.shapes.get(name, None)\r\n",
    "      new_dim = shape[i]\r\n",
    "\r\n",
    "      if (broadcast and new_dim == 1):\r\n",
    "        continue\r\n",
    "\r\n",
    "      if old_dim is None:\r\n",
    "        # If the axis name is new, add its length to the cache.\r\n",
    "        self.shapes[name] = new_dim\r\n",
    "        continue\r\n",
    "\r\n",
    "      if new_dim != old_dim:\r\n",
    "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\r\n",
    "                         f\"    found: {new_dim}\\n\"\r\n",
    "                         f\"    expected: {old_dim}\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carregando os dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#path_to_zip = tf.keras.utils.get_file('spa-eng.zip', origin='C://Users/ricar/Downloads/spa-eng.zip', extract=True)\r\n",
    "path_of_file = pathlib.Path('./data/dataset.txt')\r\n",
    "\r\n",
    "# função para carregar os dados\r\n",
    "def load_data(path):\r\n",
    "  text = path.read_text(encoding='utf-8')\r\n",
    "  \r\n",
    "  #pairs vai ter várias listas, com dois elementos em cada uma: a palavra em Inglês e Espanhol\r\n",
    "  lines = text.splitlines()\r\n",
    "  pairs = [line.split('\\t') for line in lines]\r\n",
    "\r\n",
    "  input = [input for target, input in pairs]\r\n",
    "  target = [target for target, input in pairs]\r\n",
    "\r\n",
    "  return target, input\r\n",
    "\r\n",
    "target, input = load_data(path_of_file)\r\n",
    "print(f'espanhol: {input[-1]}\\n')\r\n",
    "print(f'inglês: {target[-1]}')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "espanhol: Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n",
      "\n",
      "inglês: If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Estruturando os dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "BUFFER_SIZE = len(input)\r\n",
    "BATCH_SIZE = 64\r\n",
    "\r\n",
    "#Vai separar todas as listas (input, targe) em partes menores, de acordo com o tamanho por parte (BUFFER_ZISE)\r\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input, target)).shuffle(BUFFER_SIZE)\r\n",
    "\r\n",
    "#Combina elementos do dataset em lotes (listas) de acordo com o tamanho (BATCH_SIZE)\r\n",
    "dataset = dataset.batch(BATCH_SIZE)\r\n",
    "\r\n",
    "for example_input_batch, example_target_batch in dataset.take(1):\r\n",
    "  print(example_input_batch[:5])\r\n",
    "  print()\r\n",
    "  print(example_target_batch[:5])\r\n",
    "  break\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[b'El ladr\\xc3\\xb3n apunt\\xc3\\xb3 al oficial de polic\\xc3\\xada con su pistola.'\n",
      " b'Preg\\xc3\\xbantale cu\\xc3\\xa1nta sopa quiere.'\n",
      " b'Ella se arrodill\\xc3\\xb3 a su lado.'\n",
      " b'\\xc2\\xbfD\\xc3\\xb3nde est\\xc3\\xa1n las llaves de Tom?'\n",
      " b'Estos ni\\xc3\\xb1os son alegres.'], shape=(5,), dtype=string)\n",
      "\n",
      "tf.Tensor(\n",
      "[b'The robber aimed his gun at the police officer.'\n",
      " b'Ask her how much soup she wants.' b'She knelt beside him.'\n",
      " b\"Where are Tom's keys?\" b'Those children are cheerful.'], shape=(5,), dtype=string)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pré processamento do texto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#Aqui neste método há várias regras para processar os textos nas línguas distintas\r\n",
    "def tf_lower_and_split_punctuation(text):\r\n",
    "  text = tf_text.normalize_utf8(text, 'NFKD')\r\n",
    "  text = tf.strings.lower(text)\r\n",
    "  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\r\n",
    "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\r\n",
    "  text = tf.strings.strip(text)\r\n",
    " \r\n",
    "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\r\n",
    "  return text\r\n",
    "\r\n",
    "tf_lower_and_split_punctuation('¿Todavía está en casa?').numpy().decode()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[START] ¿ todavia esta en casa ? [END]'"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vetorização dos textos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "max_vocabulary_size = 5000\r\n",
    "\r\n",
    "#O adapt é usado para fazer um treinamento dos vetores em cima dos dados \r\n",
    "\r\n",
    "#camada de vetorização do input \r\n",
    "input_text_processor = preprocessing.TextVectorization(standardize=tf_lower_and_split_punctuation, max_tokens=max_vocabulary_size)\r\n",
    "input_text_processor.adapt(input)\r\n",
    "\r\n",
    "#camada de vetorização do output \r\n",
    "output_text_processor = preprocessing.TextVectorization(standardize=tf_lower_and_split_punctuation, max_tokens=max_vocabulary_size)\r\n",
    "output_text_processor.adapt(target)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Usando as camadas vetorizadas\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#As camadas têm capacidade agora de converter uma lista (ou lote) de strings em textos\r\n",
    "#E com o vocabulário, pode-se converter os tokens para textos\r\n",
    "\r\n",
    "print(f'Vocabulário da camada input: {input_text_processor.get_vocabulary()[:10]}')\r\n",
    "print(f'Vocabulário da camada output: {output_text_processor.get_vocabulary()[:10]}\\n')\r\n",
    "\r\n",
    "example_tokens = input_text_processor(example_input_batch)\r\n",
    "\r\n",
    "print(f'Exemplo de tokens: {example_tokens[:3, :10]}\\n')\r\n",
    "print(f'Tokens da primeira frase: {example_tokens[0]}\\n')\r\n",
    "\r\n",
    "input_vocab = np.array(input_text_processor.get_vocabulary())\r\n",
    "tokens = input_vocab[example_tokens[0].numpy()]\r\n",
    "first_phrase = ' '.join(tokens)\r\n",
    "\r\n",
    "print(f'Primeira frase \"destokenizada\": {tokens}\\n')\r\n",
    "print(f'Primeira frase \"destokenizada\" e formatada: {first_phrase}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vocabulário da camada input: ['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']\n",
      "Vocabulário da camada output: ['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']\n",
      "\n",
      "Exemplo de tokens: [[   2    7 1191 2694   37 2852    6  255   27   25]\n",
      " [   2 1901 1874 1117  106    4    3    0    0    0]\n",
      " [   2   29   17    1    8   25  360    4    3    0]]\n",
      "\n",
      "Tokens da primeira frase: [   2    7 1191 2694   37 2852    6  255   27   25 1704    4    3    0\n",
      "    0    0    0]\n",
      "\n",
      "Primeira frase \"destokenizada\": ['[START]' 'el' 'ladron' 'apunto' 'al' 'oficial' 'de' 'policia' 'con' 'su'\n",
      " 'pistola' '.' '[END]' '' '' '' '']\n",
      "\n",
      "Primeira frase \"destokenizada\" e formatada: [START] el ladron apunto al oficial de policia con su pistola . [END]    \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelos"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Codificador"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "#Variáveis \"globais\"\r\n",
    "\r\n",
    "embedding_dim = 256 #Dimensão da camada de embedding\r\n",
    "units = 1024 #"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# Codificador\r\n",
    "\r\n",
    "# Considerações: o uso da classe ShapeChecker() serve para verificar os formatos dos tensores\r\n",
    "#                o codificador precisa retornar uma saída codificada e também o seu estado para que seja passado ao decodificador  \r\n",
    "\r\n",
    "# O codificador, simplificando, é uma camada da inteligência de tradução, por isso herda de Layer\r\n",
    "class Encoder(tf.keras.layers.Layer):\r\n",
    "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\r\n",
    "    super(Encoder, self).__init__()\r\n",
    "    self.enc_units = enc_units\r\n",
    "    self.input_vocab_size = input_vocab_size\r\n",
    "\r\n",
    "    #Camada de embedding para converter tokens em vetores \r\n",
    "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size, embedding_dim)\r\n",
    "\r\n",
    "    #Essa é a camada que processa os vetores sequencialmente (camada RNN) \r\n",
    "    self.gru = tf.keras.layers.GRU(\r\n",
    "      self.enc_units,\r\n",
    "      return_sequences=True,\r\n",
    "      return_state=True,\r\n",
    "      recurrent_initializer='glorot_uniform'\r\n",
    "    )\r\n",
    "  \r\n",
    "  def call(self, tokens, state=None):\r\n",
    "    shape_checker = ShapeChecker()\r\n",
    "    shape_checker(tokens, ('batch', 's'))\r\n",
    "\r\n",
    "    #Camada de embedding que procura os tokens\r\n",
    "    vectors = self.embedding(tokens)\r\n",
    "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\r\n",
    "\r\n",
    "    #Camada RNN que processa a sequencia de vetores\r\n",
    "    output, state = self.gru(vectors, initial_state=state)\r\n",
    "    shape_checker(output, ('batch', 's', 'enc_units'))\r\n",
    "    shape_checker(state, ('batch', 'enc_units'))\r\n",
    "\r\n",
    "    return output, state"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testando o codificador"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "#Convertendo a entrada (texto) para tokens\r\n",
    "example_tokens = input_text_processor(example_input_batch)\r\n",
    "\r\n",
    "#Tenho 64 frases dentro de \"example_input_batch\"\r\n",
    "print(f'formato do lote de entrada (lote de frases): {example_input_batch.shape}')\r\n",
    "print(f'algumas frases do lote: {example_input_batch[:2]}\\n')\r\n",
    "\r\n",
    "#Tenho 64 lista de tokens, cada lista contendo 15 tokens\r\n",
    "print(f'formato do lote de tokens de entrada (lote de tokens): {example_tokens.shape}')\r\n",
    "print(f'alguns tokens que estão sendo passados: {example_tokens[:1]}\\n')\r\n",
    "\r\n",
    "#Codificando a sequência de tokens de entrada\r\n",
    "encoder = Encoder(input_text_processor.vocabulary_size(), embedding_dim, units)\r\n",
    "example_enc_output, example_enc_state = encoder(example_tokens)\r\n",
    "\r\n",
    "#Eu tenho uma saída, codificada, com o seguinte shape (x, 15, 1024)\r\n",
    "#Onde x é quantidade de frases que passei, 15 é quantidade de tokens e 1024 é a dimensão de cada embedding \r\n",
    "print(f'Saída codificada, shape (batch, s, units): {example_enc_output.shape}')\r\n",
    "print(f'Estado de saída, shape (batch, units): {example_enc_state.shape}\\n')\r\n",
    "\r\n",
    "#Cada frase vai ter uma lista de tokens que foram vetorizados à embeddings (transformado em uma lista de valores de embeddings)\r\n",
    "#Então agora temos 15 listas, referente ao valor dos tokens, e cada lista tem uma lista com 1024 valores de embedding \r\n",
    "print(f'Primeira frase: {example_enc_output[0].shape}')\r\n",
    "print(f'Valor de embedding do primeiro token: {example_enc_output[0][0].shape}')\r\n",
    "\r\n",
    "#----\r\n",
    "print(f'\\nInput batch, shape (batch): {example_input_batch.shape}')\r\n",
    "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\r\n",
    "print(f'Input batch tokens, shape (batch, s): {example_enc_output.shape}')\r\n",
    "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "formato do lote de entrada (lote de frases): (64,)\n",
      "algumas frases do lote: [b'El ladr\\xc3\\xb3n apunt\\xc3\\xb3 al oficial de polic\\xc3\\xada con su pistola.'\n",
      " b'Preg\\xc3\\xbantale cu\\xc3\\xa1nta sopa quiere.']\n",
      "\n",
      "formato do lote de tokens de entrada (lote de tokens): (64, 17)\n",
      "alguns tokens que estão sendo passados: [[   2    7 1191 2694   37 2852    6  255   27   25 1704    4    3    0\n",
      "     0    0    0]]\n",
      "\n",
      "Saída codificada, shape (batch, s, units): (64, 17, 1024)\n",
      "Estado de saída, shape (batch, units): (64, 1024)\n",
      "\n",
      "Primeira frase: (17, 1024)\n",
      "Valor de embedding do primeiro token: (1024,)\n",
      "\n",
      "Input batch, shape (batch): (64,)\n",
      "Input batch tokens, shape (batch, s): (64, 17)\n",
      "Input batch tokens, shape (batch, s): (64, 17, 1024)\n",
      "Encoder state, shape (batch, units): (64, 1024)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Atenção  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# a cabeça da camada de atenção a ser usada aqui é a Bahdanau's additive attention. \r\n",
    "# ref: https://arxiv.org/pdf/1409.0473.pdf\r\n",
    "\r\n",
    "class BahadanauAttention(tf.keras.layers.Layer):\r\n",
    "    def __init__(self, units):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.W1 = tf.keras.layers.Dense(units, use_bias=False)\r\n",
    "        self.W2 = tf.keras.layers.Dense(units, use_bias=False)\r\n",
    "\r\n",
    "        self.attention = tf.keras.layers.AdditiveAttention()\r\n",
    "\r\n",
    "    #query vai ser algo gerado pelo decodificador\r\n",
    "    #value é a saída do codificador\r\n",
    "    #maks vai servir para excluir o padding\r\n",
    "    def call(self, query, value, mask):\r\n",
    "        shape_checker = ShapeChecker()\r\n",
    "        shape_checker(query, ('batch', 't', 'query_units')) \r\n",
    "        shape_checker(value, ('batch', 's', 'value_units')) \r\n",
    "        shape_checker(mask, ('batch', 's')) \r\n",
    "\r\n",
    "        w1_query = self.W1(query)\r\n",
    "        shape_checker(w1_query, ('batch', 't', 'attn_units'))\r\n",
    "\r\n",
    "        w2_key = self.W2(value)\r\n",
    "        shape_checker(w2_key, ('batch', 's', 'attn_units'))\r\n",
    "\r\n",
    "        query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\r\n",
    "        value_mask = mask\r\n",
    "\r\n",
    "        context_vector, attention_weights = self.attention(\r\n",
    "            inputs = [w1_query, value, w2_key],\r\n",
    "            mask=[query_mask, value_mask],\r\n",
    "            return_attention_scores = True,\r\n",
    "        )\r\n",
    "        shape_checker(context_vector, ('batch', 't', 'value_units'))\r\n",
    "        shape_checker(attention_weights, ('batch', 't', 's'))\r\n",
    "\r\n",
    "        return context_vector, attention_weights"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testando a camada de atenção"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "attention_layer = BahadanauAttention(units)\r\n",
    "print((example_tokens != 0).shape)\r\n",
    "\r\n",
    "#Este é um exemplo de consulta que o decodificador fará\r\n",
    "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\r\n",
    "\r\n",
    "#\r\n",
    "context_vector, attention_weights = attention_layer(query=example_attention_query, value=example_enc_output, mask=(example_tokens != 0))\r\n",
    "\r\n",
    "print(f'Shape do resultado do vetor de atenção: {context_vector.shape}')\r\n",
    "print(f'Shape dos pesos retornados da camada de atenção: {attention_weights.shape}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(64, 17)\n",
      "Shape do resultado do vetor de atenção: (64, 2, 1024)\n",
      "Shape dos pesos retornados da camada de atenção: (64, 2, 17)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('tcc': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "f16f457e3894a9ee51386b4536b92eca290ee443d329ce528bb63897bfdf32bc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}