{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.11 64-bit ('tcc': conda)"},"language_info":{"name":"python","version":"3.8.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f16f457e3894a9ee51386b4536b92eca290ee443d329ce528bb63897bfdf32bc"},"colab":{"name":"translater.ipynb","provenance":[],"collapsed_sections":["gsQAuR5qzcUG","NpH6hUFAzcUJ","Oj5z7VoGzcUX","_ez0ihn_zcUf","n0aQM1qFzcUm","t9fNgawuzcUs","xLwSwZbGzcU7","97rSLgnZIinz","G6elcseinNQh","UglfqkgcnZeO","6ymy8gs9nmKP","XjO4G3RAoe_G","fnrdwwj6H-33"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"n5HHr6m3zcTs"},"source":["\n","# Configuração"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6WtnqdpSvlK","executionInfo":{"status":"ok","timestamp":1633563246057,"user_tz":180,"elapsed":4925,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"5d248504-235f-483f-8fdf-5bad353f11e8"},"source":["#Requirido apenas se estiver executando no colab\n","!pip install tensorflow_text"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_text\n","  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow<2.7,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.6.0)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.1.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.1.2)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.12)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.12.1)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.17.3)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.7.4.3)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.12.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.2.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.1.0)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (5.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (0.37.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.6.3)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (3.3.0)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (2.6.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.41.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.19.5)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.7,>=2.6.0->tensorflow_text) (1.15.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.3.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.8.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.7.2)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (4.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (2021.5.30)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.7,>=2.6.0->tensorflow_text) (3.6.0)\n","Installing collected packages: tensorflow-text\n","Successfully installed tensorflow-text-2.6.0\n"]}]},{"cell_type":"code","metadata":{"id":"PhG5tlpFzcT5","executionInfo":{"status":"ok","timestamp":1633563248615,"user_tz":180,"elapsed":2573,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["# Tipagem\n","import typing \n","import string\n","from typing import Any, Tuple, NamedTuple\n","from string import digits\n","\n","# Auxiliares\n","import pathlib\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","# Core\n","import tensorflow as tf\n","import tensorflow_text as tf_text\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","# Classe auxliar\n","class ShapeChecker():\n","  def __init__(self):\n","    # Keep a cache of every axis-name seen\n","    self.shapes = {}\n","\n","  def __call__(self, tensor, names, broadcast=False):\n","    if not tf.executing_eagerly():\n","      return\n","\n","    if isinstance(names, str):\n","      names = (names,)\n","\n","    shape = tf.shape(tensor)\n","    rank = tf.rank(tensor)\n","\n","    if rank != len(names):\n","      raise ValueError(f'Rank mismatch:\\n'\n","                       f'    found {rank}: {shape.numpy()}\\n'\n","                       f'    expected {len(names)}: {names}\\n')\n","\n","    for i, name in enumerate(names):\n","      if isinstance(name, int):\n","        old_dim = name\n","      else:\n","        old_dim = self.shapes.get(name, None)\n","      new_dim = shape[i]\n","\n","      if (broadcast and new_dim == 1):\n","        continue\n","\n","      if old_dim is None:\n","        # If the axis name is new, add its length to the cache.\n","        self.shapes[name] = new_dim\n","        continue\n","\n","      if new_dim != old_dim:\n","        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n","                         f\"    found: {new_dim}\\n\"\n","                         f\"    expected: {old_dim}\\n\")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gsQAuR5qzcUG"},"source":["# Dados"]},{"cell_type":"markdown","metadata":{"id":"NpH6hUFAzcUJ"},"source":["## Carregando os dados"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvtGSrTozcUK","executionInfo":{"status":"ok","timestamp":1633563248922,"user_tz":180,"elapsed":384,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"8765d3e3-d519-4065-8e4e-7862d897c471"},"source":["# Para baixar os dados (caso esteja usando o colab):\n","path_to_zip = tf.keras.utils.get_file(\n","    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n","    extract=True)\n","\n","path_of_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'\n","\n","# função para carregar os dados\n","def load_data(path):\n","  text = path.read_text(encoding='utf-8')\n","  \n","  #pairs vai ter várias listas, com dois elementos em cada uma: a palavra em Inglês e Espanhol\n","  lines = text.splitlines()\n","  pairs = [line.split('\\t') for line in lines]\n","\n","  input = [input for target, input in pairs]\n","  target = [target for target, input in pairs]\n","\n","  return target, input\n","\n","target, input = load_data(path_of_file)\n","print(f'\\nespanhol: {input[-1]}')\n","print(f'inglês: {target[-1]}')\n"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","2646016/2638744 [==============================] - 0s 0us/step\n","2654208/2638744 [==============================] - 0s 0us/step\n","\n","espanhol: Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n","inglês: If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Oj5z7VoGzcUX"},"source":["## Estruturando os dados"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31eoJy6QzcUb","executionInfo":{"status":"ok","timestamp":1633563255614,"user_tz":180,"elapsed":6705,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"40972f6e-bddf-4ad2-949e-6f9f8740bd59"},"source":["print(f'tamanho da lista de entradas: {len(input)}')\n","print(f'tamanho da lista de entradas: {len(target)}')\n","\n","BUFFER_SIZE = len(input)\n","BATCH_SIZE = 64\n","\n","#Vai separar todas as listas (input, target) em partes menores, de acordo com o tamanho por parte (BUFFER_ZISE)\n","dataset = tf.data.Dataset.from_tensor_slices((input, target)).shuffle(BUFFER_SIZE)\n","\n","#Combina elementos do dataset em lotes (listas) de acordo com o tamanho (BATCH_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","\n","for example_input_batch, example_target_batch in dataset.take(1):\n","  print(example_input_batch[:5])\n","  print()\n","  print(example_target_batch[:5])\n","  break\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tamanho da lista de entradas: 118964\n","tamanho da lista de entradas: 118964\n","tf.Tensor(\n","[b'Lamento mucho haberte hecho esperar tanto.'\n"," b'Ahora un computador es una absoluta necesidad.'\n"," b'\\xc2\\xbfElla habla ingl\\xc3\\xa9s?' b'\\xc2\\xbfEst\\xc3\\xa1s mirando?'\n"," b'Casi fui robado.'], shape=(5,), dtype=string)\n","\n","tf.Tensor(\n","[b'I feel bad about having made you wait so long.'\n"," b'A computer is an absolute necessity now.' b'Does she speak English?'\n"," b'Are you looking?' b'I almost got robbed.'], shape=(5,), dtype=string)\n"]}]},{"cell_type":"markdown","metadata":{"id":"_ez0ihn_zcUf"},"source":["## Pré processamento do texto"]},{"cell_type":"code","metadata":{"id":"5BmiGqOhzcUh","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1633563255645,"user_tz":180,"elapsed":67,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"a923d7aa-29b7-4577-8f87-87f9f2fe8a62"},"source":["#Aqui neste método há várias regras para processar os textos nas línguas distintas\n","def tf_lower_and_split_punctuation(text):\n","  text = tf_text.normalize_utf8(text, 'NFKD')\n","  text = tf.strings.lower(text)\n","  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n","  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n","  text = tf.strings.strip(text)\n"," \n","  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n","  return text\n","\n","tf_lower_and_split_punctuation('¿Todavía está en casa?').numpy().decode()\n"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[START] ¿ todavia esta en casa ? [END]'"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"n0aQM1qFzcUm"},"source":["## Vetorização dos textos"]},{"cell_type":"code","metadata":{"id":"_5diTGpVzcUq","executionInfo":{"status":"ok","timestamp":1633563269458,"user_tz":180,"elapsed":13856,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["max_vocabulary_size = 5000\n","\n","#O adapt é usado para fazer um treinamento dos vetores em cima dos dados \n","\n","#camada de vetorização do input \n","input_text_processor = preprocessing.TextVectorization(standardize=tf_lower_and_split_punctuation, max_tokens=max_vocabulary_size)\n","input_text_processor.adapt(input)\n","\n","#camada de vetorização do output \n","output_text_processor = preprocessing.TextVectorization(standardize=tf_lower_and_split_punctuation, max_tokens=max_vocabulary_size)\n","output_text_processor.adapt(target)\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t9fNgawuzcUs"},"source":["## Usando as camadas vetorizadas\n"]},{"cell_type":"code","metadata":{"id":"nKYh9quGzcUu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633563269495,"user_tz":180,"elapsed":90,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"92fa9518-fa54-4109-99f0-7c92d4e78f51"},"source":["#As camadas têm capacidade agora de converter uma lista (ou lote) de strings em textos\n","#E com o vocabulário, pode-se converter os tokens para textos\n","\n","print(f'Vocabulário da camada input: {input_text_processor.get_vocabulary()[:10]}')\n","print(f'Vocabulário da camada output: {output_text_processor.get_vocabulary()[:10]}\\n')\n","\n","example_tokens = input_text_processor(example_input_batch)\n","\n","print(f'Exemplo de tokens: {example_tokens[:3, :10]}\\n')\n","print(f'Tokens da primeira frase: {example_tokens[0]}\\n')\n","\n","input_vocab = np.array(input_text_processor.get_vocabulary())\n","tokens = input_vocab[example_tokens[0].numpy()]\n","first_phrase = ' '.join(tokens)\n","\n","print(f'Primeira frase \"destokenizada\": {tokens}\\n')\n","print(f'Primeira frase \"destokenizada\" e formatada: {first_phrase}')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulário da camada input: ['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']\n","Vocabulário da camada output: ['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']\n","\n","Exemplo de tokens: [[   2  806   77 1086  162  416  253    4    3    0]\n"," [   2   90   16 1237   15   23    1 1810    4    3]\n"," [   2   13   29  219  151   12    3    0    0    0]]\n","\n","Tokens da primeira frase: [   2  806   77 1086  162  416  253    4    3    0    0    0    0    0\n","    0    0    0    0    0    0]\n","\n","Primeira frase \"destokenizada\": ['[START]' 'lamento' 'mucho' 'haberte' 'hecho' 'esperar' 'tanto' '.'\n"," '[END]' '' '' '' '' '' '' '' '' '' '' '']\n","\n","Primeira frase \"destokenizada\" e formatada: [START] lamento mucho haberte hecho esperar tanto . [END]           \n"]}]},{"cell_type":"markdown","metadata":{"id":"221YhUoOzcUw"},"source":["# Modelos"]},{"cell_type":"markdown","metadata":{"id":"sU_wrKlnzcUy"},"source":["## Codificador"]},{"cell_type":"code","metadata":{"id":"1xAjOhUrzcU2","executionInfo":{"status":"ok","timestamp":1633563269498,"user_tz":180,"elapsed":73,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["#Variáveis \"globais\"\n","\n","embedding_dim = 256 #Dimensão da camada de embedding\n","units = 1024 #"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvBxONgQzcU5","executionInfo":{"status":"ok","timestamp":1633563269508,"user_tz":180,"elapsed":79,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["# Codificador\n","\n","# Considerações: o uso da classe ShapeChecker() serve para verificar os formatos dos tensores\n","#                o codificador precisa retornar uma saída codificada e também o seu estado para que seja passado ao decodificador  \n","\n","# O codificador, simplificando, é uma camada da inteligência de tradução, por isso herda de Layer\n","class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n","    super(Encoder, self).__init__()\n","    self.enc_units = enc_units\n","    self.input_vocab_size = input_vocab_size\n","\n","    #Camada de embedding para converter tokens em vetores \n","    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n","                                               embedding_dim)\n","\n","    #Essa é a camada que processa os vetores sequencialmente (camada RNN) \n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                   # Return the sequence and state\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","  \n","  def call(self, tokens, state=None):\n","    shape_checker = ShapeChecker()\n","    shape_checker(tokens, ('batch', 's'))\n","\n","    #Camada de embedding que procura os tokens\n","    vectors = self.embedding(tokens)\n","    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n","\n","    #Camada RNN que processa a sequencia de vetores\n","    output, state = self.gru(vectors, initial_state=state)\n","    shape_checker(output, ('batch', 's', 'enc_units'))\n","    shape_checker(state, ('batch', 'enc_units'))\n","\n","    return output, state"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xLwSwZbGzcU7"},"source":["### Testando o codificador"]},{"cell_type":"code","metadata":{"id":"L50qx9VszcU8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633563272072,"user_tz":180,"elapsed":2628,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"55969298-17a2-46a6-a5e7-1145225a3182"},"source":["#Convertendo a entrada (texto) para tokens\n","example_tokens = input_text_processor(example_input_batch)\n","\n","#Tenho 64 frases dentro de \"example_input_batch\"\n","print(f'formato do lote de entrada (lote de frases): {example_input_batch.shape}')\n","print(f'algumas frases do lote: {example_input_batch[:2]}\\n')\n","\n","#Tenho 64 lista de tokens, cada lista contendo 15 tokens\n","print(f'formato do lote de tokens de entrada (lote de tokens): {example_tokens.shape}')\n","print(f'alguns tokens que estão sendo passados: {example_tokens[:1]}\\n')\n","\n","#Codificando a sequência de tokens de entrada\n","encoder = Encoder(input_text_processor.vocabulary_size(),\n","                  embedding_dim, units)\n","example_enc_output, example_enc_state = encoder(example_tokens)\n","\n","#Eu tenho uma saída, codificada, com o seguinte shape (x, 15, 1024)\n","#Onde x é quantidade de frases que passei, 15 é quantidade de tokens e 1024 é a dimensão de cada embedding \n","print(f'Saída codificada, shape (batch, s, units): {example_enc_output.shape}')\n","print(f'Estado de saída, shape (batch, units): {example_enc_state.shape}\\n')\n","\n","#Cada frase vai ter uma lista de tokens que foram vetorizados à embeddings (transformado em uma lista de valores de embeddings)\n","#Então agora temos 15 listas, referente ao valor dos tokens, e cada lista tem uma lista com 1024 valores de embedding \n","print(f'Primeira frase: {example_enc_output[0].shape}')\n","print(f'Valor de embedding do primeiro token: {example_enc_output[0][0].shape}')\n","\n","#----\n","print(f'\\nInput batch, shape (batch): {example_input_batch.shape}')\n","print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n","print(f'Input batch tokens, shape (batch, s): {example_enc_output.shape}')\n","print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')\n"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["formato do lote de entrada (lote de frases): (64,)\n","algumas frases do lote: [b'Lamento mucho haberte hecho esperar tanto.'\n"," b'Ahora un computador es una absoluta necesidad.']\n","\n","formato do lote de tokens de entrada (lote de tokens): (64, 20)\n","alguns tokens que estão sendo passados: [[   2  806   77 1086  162  416  253    4    3    0    0    0    0    0\n","     0    0    0    0    0    0]]\n","\n","Saída codificada, shape (batch, s, units): (64, 20, 1024)\n","Estado de saída, shape (batch, units): (64, 1024)\n","\n","Primeira frase: (20, 1024)\n","Valor de embedding do primeiro token: (1024,)\n","\n","Input batch, shape (batch): (64,)\n","Input batch tokens, shape (batch, s): (64, 20)\n","Input batch tokens, shape (batch, s): (64, 20, 1024)\n","Encoder state, shape (batch, units): (64, 1024)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Mllb_o2XzcU_"},"source":["## Atenção  "]},{"cell_type":"code","metadata":{"id":"eXiW5geHzcVB","executionInfo":{"status":"ok","timestamp":1633563272075,"user_tz":180,"elapsed":94,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["# a cabeça da camada de atenção a ser usada aqui é a Bahdanau's additive attention. \n","# ref: https://arxiv.org/pdf/1409.0473.pdf\n","\n","class BahdanauAttention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super().__init__()\n","    # For Eqn. (4), the  Bahdanau attention\n","    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n","    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n","\n","    self.attention = tf.keras.layers.AdditiveAttention()\n","\n","  #query vai ser algo gerado pelo decodificador\n","  #value é a saída do codificador\n","  #maks vai servir para excluir o padding\n","  def call(self, query, value, mask):\n","    shape_checker = ShapeChecker()\n","    shape_checker(query, ('batch', 't', 'query_units'))\n","    shape_checker(value, ('batch', 's', 'value_units'))\n","    shape_checker(mask, ('batch', 's'))\n","\n","    # From Eqn. (4), `W1@ht`.\n","    w1_query = self.W1(query)\n","    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n","\n","    # From Eqn. (4), `W2@hs`.\n","    w2_key = self.W2(value)\n","    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n","\n","    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n","    value_mask = mask\n","\n","    context_vector, attention_weights = self.attention(\n","        inputs = [w1_query, value, w2_key],\n","        mask=[query_mask, value_mask],\n","        return_attention_scores = True,\n","    )\n","    shape_checker(context_vector, ('batch', 't', 'value_units'))\n","    shape_checker(attention_weights, ('batch', 't', 's'))\n","\n","    return context_vector, attention_weights"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HlsAb3p5zcVF"},"source":["### Testando a camada de atenção"]},{"cell_type":"code","metadata":{"id":"bGIq6JDvzcVJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633563274163,"user_tz":180,"elapsed":2177,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"dc5cfa65-eccb-40d7-996e-4b2ff70f127d"},"source":["attention_layer = BahdanauAttention(units)\n","print((example_tokens != 0).shape)\n","\n","#Este é um exemplo de consulta que o decodificador fará\n","example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n","\n","#\n","context_vector, attention_weights = attention_layer(\n","    query=example_attention_query,\n","    value=example_enc_output,\n","    mask=(example_tokens != 0))\n","\n","print(f'Shape do resultado do vetor de atenção: {context_vector.shape}')\n","print(f'Shape dos pesos retornados da camada de atenção: {attention_weights.shape}')"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 20)\n","Shape do resultado do vetor de atenção: (64, 2, 1024)\n","Shape dos pesos retornados da camada de atenção: (64, 2, 20)\n"]}]},{"cell_type":"markdown","metadata":{"id":"CiPRhMndzcVO"},"source":["## Decodificador"]},{"cell_type":"code","metadata":{"id":"nXv4G53tzcVP","executionInfo":{"status":"ok","timestamp":1633563274164,"user_tz":180,"elapsed":27,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["#Como são diversos tensores que o decoder recebe e retorna, foi criada classes auxiliares \n","class DecoderInput(typing.NamedTuple):\n","  new_tokens: Any\n","  enc_output: Any\n","  mask: Any\n","\n","class DecoderOutput(typing.NamedTuple):\n","  logits: Any\n","  attention_weights: Any\n","\n","#O decodificador vai receber a saída inteira do codificador para gerar as previsões.\n","class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n","    super(Decoder, self).__init__()\n","    self.dec_units = dec_units\n","    self.output_vocab_size = output_vocab_size\n","    self.embedding_dim = embedding_dim\n","\n","    #1º passo: criar camada de Embedding para vetorizar os IDs de tokens\n","    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n","                                                embedding_dim)\n","\n","    #2º passo: a camada GRU para gerar as previsões \n","    self.gru = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    \n","    #3º passo: gerar a camada de atenção para melhorar a previsão. A saída da camada GRU vai servir como query para esta camada\n","    self.attention = BahdanauAttention(self.dec_units)\n","\n","    #4º passo: \n","    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n","                                    use_bias=False)\n","\n","    #5º passo: uma camada que irá produzir previsões logísticas para cada token de saída\n","    self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n","\n","def call(self,\n","         inputs: DecoderInput,\n","         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n","  shape_checker = ShapeChecker()\n","  shape_checker(inputs.new_tokens, ('batch', 't'))\n","  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n","  shape_checker(inputs.mask, ('batch', 's'))\n","        \n","  if state is not None:\n","    shape_checker(state, ('batch', 'dec_units'))\n","        \n","  #1º passo. Vetorizando os tokens\n","  vectors = self.embedding(inputs.new_tokens)\n","  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n","        \n","  #2º passo. Processa o vetor de embeddings com a camada GRU\n","  rnn_output, state = self.gru(vectors, initial_state=state)\n","        \n","  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n","  shape_checker(state, ('batch', 'dec_units'))\n","        \n","  #3º passo. Usa a saída da camda GRU como query para a camada de atenção\n","  context_vector, attention_weights = self.attention(\n","      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n","  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n","  shape_checker(attention_weights, ('batch', 't', 's'))\n","        \n","  #4º passo. Eqn. (3): Join the context_vector and rnn_output [ct; ht] shape: (batch t, value_units + query_units)\n","  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n","        \n","  #5º passo. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n","  attention_vector = self.Wc(context_and_rnn_output)\n","  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n","        \n","  #6º passo. Gera as previsões logísticas:\n","  logits = self.fc(attention_vector)\n","  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n","        \n","  return DecoderOutput(logits, attention_weights), state\n","\n","\n","Decoder.call = call"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nT74l8djzcVS"},"source":["### Testando o decodificador"]},{"cell_type":"code","metadata":{"id":"bQgN3McMzcVV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633563274698,"user_tz":180,"elapsed":556,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"afe1489b-8cbd-464a-a192-1dcc12a83e3c"},"source":["# Relembrando os dados\n","\n","print(f'frase: {example_target_batch[1]}')\n","print(f'frase vetorizada: {output_text_processor(example_target_batch[1])}')\n","\n","#O decoder precisa ter o vocabulário para converter os tokens\n","#A camada de embedding precisa ter o mesmo tamanho da camada do codificador\n","print(f'embedding: {embedding_dim}')\n","print(f'unidades: {units}') #Relemebrar\n","\n","decoder = Decoder(output_text_processor.vocabulary_size(),\n","                  embedding_dim, units)\n","\n","example_output_tokens = output_text_processor(example_target_batch)\n","start_index = output_text_processor.get_vocabulary().index('[START]')\n","first_token = tf.constant([[start_index]] * example_output_tokens.shape[0]) #revisar isso\n","\n","# Testando o decoder\n","dec_result, dec_state = decoder(\n","    inputs = DecoderInput(new_tokens=first_token,\n","                          enc_output=example_enc_output,\n","                          mask=(example_tokens != 0)),\n","    state = example_enc_state\n",")\n","\n","print(f'\\nshape do cálculo logístico: (batch_size, t, output_vocab_size) {dec_result.logits.shape}')\n","print(f'shape do estado do decoder: (batch_size, dec_units) {dec_state.shape}')\n","\n","sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n","\n","#decodificando os tokens usando o vocabulário\n","vocab = np.array(output_text_processor.get_vocabulary())\n","first_word = vocab[sampled_token.numpy()]\n","\n","print(f'\\nVocabulário: {vocab}')\n","print(f'Palavras: {first_word[:5]}')\n","\n","dec_result, dec_state = decoder(\n","    DecoderInput(sampled_token,\n","                 example_enc_output,\n","                 mask=(example_tokens != 0)),\n","    state=dec_state)\n","\n","sampled_token = tf.random.categorical(dec_result.logits[:, 0, :], num_samples=1)\n","first_word = vocab[sampled_token.numpy()]\n","print(f'\\nPalavras: {first_word[:5]}')"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["frase: b'A computer is an absolute necessity now.'\n","frase vetorizada: [   2   10  576   12   72 2779 3285   95    4    3]\n","embedding: 256\n","unidades: 1024\n","\n","shape do cálculo logístico: (batch_size, t, output_vocab_size) (64, 1, 5000)\n","shape do estado do decoder: (batch_size, dec_units) (64, 1024)\n","\n","Vocabulário: ['' '[UNK]' '[START]' ... 'productive' 'printer' 'principles']\n","Palavras: [['lead']\n"," ['oranges']\n"," ['punish']\n"," ['singapore']\n"," ['divide']]\n","\n","Palavras: [['remarkable']\n"," ['silk']\n"," ['sun']\n"," ['potatoes']\n"," ['boxes']]\n"]}]},{"cell_type":"markdown","metadata":{"id":"S3r48mP_zcVZ"},"source":["# Treinamento"]},{"cell_type":"markdown","metadata":{"id":"97rSLgnZIinz"},"source":["\n","### Construindo a função de perda"]},{"cell_type":"code","metadata":{"id":"12RwHwFxmCUa","executionInfo":{"status":"ok","timestamp":1633563274702,"user_tz":180,"elapsed":73,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["#Como o tradutor é uma inteligência mais complexa, necessita de criar as próprias funções que são utilizadas no treinamento\n","#No caso desta, precisa da: função de perda, otimizador, atualizador de pesos e o ciclo de treinos (epochs)\n","\n","class MaskedLoss(tf.keras.losses.Loss):\n","  def __init__(self):\n","    self.name = 'masked_loss'\n","    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","\n","  def __call__(self, y_true, y_pred):\n","    shape_checker = ShapeChecker()\n","    shape_checker(y_true, ('batch', 't'))\n","    shape_checker(y_pred, ('batch', 't', 'logits'))\n","\n","    # Calcula a perda para cada frase no lote (sequência de frases)\n","    loss = self.loss(y_true, y_pred)\n","    shape_checker(loss, ('batch', 't'))\n","\n","    # Mascara as perdas no padding (? revisar)\n","    mask = tf.cast(y_true != 0, tf.float32)\n","    shape_checker(mask, ('batch', 't'))\n","    loss *= mask\n","\n","    return tf.reduce_sum(loss)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G6elcseinNQh"},"source":["### Classe de treinamento"]},{"cell_type":"code","metadata":{"id":"ZykdGFwnzcVa","executionInfo":{"status":"ok","timestamp":1633563274707,"user_tz":180,"elapsed":72,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["class TrainTranslator(tf.keras.Model):\n","  def __init__(self, embedding_dim, units,\n","               input_text_processor,\n","               output_text_processor, \n","               use_tf_function=True):\n","    super().__init__()\n","    # Build the encoder and decoder\n","    encoder = Encoder(input_text_processor.vocabulary_size(),\n","                      embedding_dim, units)\n","    decoder = Decoder(output_text_processor.vocabulary_size(),\n","                      embedding_dim, units)\n","\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.input_text_processor = input_text_processor\n","    self.output_text_processor = output_text_processor\n","    self.use_tf_function = use_tf_function\n","    self.shape_checker = ShapeChecker()\n","\n","  def train_step(self, inputs):\n","    self.shape_checker = ShapeChecker()\n","    if self.use_tf_function:\n","      return self._tf_train_step(inputs)\n","    else:\n","      return self._train_step(inputs)\n"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UglfqkgcnZeO"},"source":["### Método de processamento dos textos (idioma de origem idioma de tradução) "]},{"cell_type":"code","metadata":{"id":"qls1sLVWS5qg","executionInfo":{"status":"ok","timestamp":1633563274711,"user_tz":180,"elapsed":70,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["def _preprocess(self, input_text, target_text):\n","  self.shape_checker(input_text, ('batch',))\n","  self.shape_checker(target_text, ('batch',))\n","\n","  # Convert the text to token IDs\n","  input_tokens = self.input_text_processor(input_text)\n","  target_tokens = self.output_text_processor(target_text)\n","  self.shape_checker(input_tokens, ('batch', 's'))\n","  self.shape_checker(target_tokens, ('batch', 't'))\n","\n","  # Convert IDs to masks.\n","  input_mask = input_tokens != 0\n","  self.shape_checker(input_mask, ('batch', 's'))\n","\n","  target_mask = target_tokens != 0\n","  self.shape_checker(target_mask, ('batch', 't'))\n","\n","  return input_tokens, input_mask, target_tokens, target_mask\n","\n","TrainTranslator._preprocess = _preprocess"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ymy8gs9nmKP"},"source":["### Método para executar o codificador e inicializar o decodificador"]},{"cell_type":"code","metadata":{"id":"qz6HKqiWoT8w","executionInfo":{"status":"ok","timestamp":1633563274713,"user_tz":180,"elapsed":62,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["def _train_step(self, inputs):\n","  input_text, target_text = inputs  \n","\n","  (input_tokens, input_mask,\n","   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n","\n","  max_target_length = tf.shape(target_tokens)[1]\n","\n","  with tf.GradientTape() as tape:\n","    # Encode the input\n","    enc_output, enc_state = self.encoder(input_tokens)\n","    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n","    self.shape_checker(enc_state, ('batch', 'enc_units'))\n","\n","    # Initialize the decoder's state to the encoder's final state.\n","    # This only works if the encoder and decoder have the same number of\n","    # units.\n","    dec_state = enc_state\n","    loss = tf.constant(0.0)\n","\n","    for t in tf.range(max_target_length-1):\n","      # Pass in two tokens from the target sequence:\n","      # 1. The current input to the decoder.\n","      # 2. The target the target for the decoder's next prediction.\n","      new_tokens = target_tokens[:, t:t+2]\n","      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n","                                             enc_output, dec_state)\n","      loss = loss + step_loss\n","\n","    # Average the loss over all non padding tokens.\n","    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n","\n","  # Apply an optimization step\n","  variables = self.trainable_variables \n","  gradients = tape.gradient(average_loss, variables)\n","  self.optimizer.apply_gradients(zip(gradients, variables))\n","\n","  # Return a dict mapping metric names to current value\n","  return {'batch_loss': average_loss}\n","\n","TrainTranslator._train_step = _train_step"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XjO4G3RAoe_G"},"source":["### Método para executar o decodificador, calcular a perda e o novo estado de decodificador "]},{"cell_type":"code","metadata":{"id":"mhpCEEgMon46","executionInfo":{"status":"ok","timestamp":1633563274717,"user_tz":180,"elapsed":63,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n","  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n","\n","  # Run the decoder one step.\n","  decoder_input = DecoderInput(new_tokens=input_token,\n","                               enc_output=enc_output,\n","                               mask=input_mask)\n","\n","  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n","  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n","  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n","  self.shape_checker(dec_state, ('batch', 'dec_units'))\n","\n","  # `self.loss` returns the total for non-padded tokens\n","  y = target_token\n","  y_pred = dec_result.logits\n","  step_loss = self.loss(y, y_pred)\n","\n","  return step_loss, dec_state\n","\n","TrainTranslator._loop_step = _loop_step"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7s5EqRVJzcVe"},"source":["### Fazendo Treinamento"]},{"cell_type":"code","metadata":{"id":"nLO2rYqNzcVf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633563286249,"user_tz":180,"elapsed":11590,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"2a45aac6-5126-4f03-f912-257da7e72e6c"},"source":["# Instanciando a classe de treino\n","translator = TrainTranslator(\n","    embedding_dim, units,\n","    input_text_processor=input_text_processor,\n","    output_text_processor=output_text_processor,\n","    use_tf_function=False)\n","\n","# Configurando a perda e otimizador\n","translator.compile(\n","    optimizer=tf.optimizers.Adam(),\n","    loss=MaskedLoss(),\n",")\n","\n","print(f'A perda deve começar perto de: {np.log(output_text_processor.vocabulary_size())}')\n","\n","for n in range(10):\n","    print(f'perda: {translator.train_step([example_input_batch, example_target_batch])}')\n"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["A perda deve começar perto de: 8.517193191416238\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.5952983>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.564265>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.505688>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=7.3315644>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=6.6482334>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=5.569319>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.7411885>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.532905>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.356859>}\n","perda: {'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.145889>}\n"]}]},{"cell_type":"code","metadata":{"id":"Bl3A6-ZQzcVh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633563292225,"user_tz":180,"elapsed":6061,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"993986e2-2ea3-4f9a-f119-14259253d1ad"},"source":["@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n","                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n","\n","def _tf_train_step(self, inputs):\n","  return self._train_step(inputs)\n","\n","TrainTranslator._tf_train_step = _tf_train_step\n","translator.use_tf_function = True\n","\n","translator.train_step([example_input_batch, example_target_batch])"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=4.0030303>}"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"YohM7-1ezcVk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633563296951,"user_tz":180,"elapsed":4797,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"06a8b6b6-439c-487e-8252-399a1b0f195e"},"source":["for n in range(10):\n","  print(translator.train_step([example_input_batch, example_target_batch]))\n","print()"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.9344873>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8984087>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.829944>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.744687>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.7342615>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.8573058>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.6834128>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.6681592>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.6264856>}\n","{'batch_loss': <tf.Tensor: shape=(), dtype=float32, numpy=3.5929286>}\n","\n"]}]},{"cell_type":"code","metadata":{"id":"Pl9cTchrzcVm","colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"status":"ok","timestamp":1633563344553,"user_tz":180,"elapsed":47630,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"064bbcf0-7deb-4357-c064-9726a381f6e4"},"source":["#Gráfico de perda\n","\n","losses = []\n","for n in range(100):\n","  print('.', end='')\n","  logs = translator.train_step([example_input_batch, example_target_batch])\n","  losses.append(logs['batch_loss'].numpy())\n","\n","print()\n","plt.plot(losses)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["....................................................................................................\n"]},{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f44a4190210>]"]},"metadata":{},"execution_count":24},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"e8JXW4SCzcVq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633566007662,"user_tz":180,"elapsed":2662957,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"5f8dba89-9c91-4a2b-8e13-700605a0b174"},"source":["#Treinamento real\n","\n","#criando uma nova cópia\n","train_translator = TrainTranslator(\n","    embedding_dim, units, \n","    input_text_processor=input_text_processor, \n","    output_text_processor=output_text_processor\n",")\n","\n","#configurando a loss e otimizador\n","train_translator.compile(\n","  optimizer=tf.optimizers.Adam(),\n","  loss=MaskedLoss(),\n",")\n","\n","#definindo a uma classe para recolher o histórico do treinamento\n","class BatchLogs(tf.keras.callbacks.Callback):\n","  def __init__(self, key):\n","    self.key = key\n","    self.logs = []\n","\n","  def on_train_batch_end(self, n, logs):\n","    self.logs.append(logs[self.key])\n","\n","batch_loss = BatchLogs('batch_loss')\n","\n","train_translator.fit(dataset, epochs=3,\n","                     callbacks=[batch_loss])"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","1859/1859 [==============================] - 871s 465ms/step - batch_loss: 2.1121\n","Epoch 2/3\n","1859/1859 [==============================] - 858s 462ms/step - batch_loss: 1.0456\n","Epoch 3/3\n","1859/1859 [==============================] - 876s 471ms/step - batch_loss: 0.8133\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f44a458a110>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"RTB8Mx03zcVs","executionInfo":{"status":"ok","timestamp":1633566007665,"user_tz":180,"elapsed":95,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["#Perda\n","# plt.plot(batch_loss.logs)\n","# plt.ylim([0, 3])\n","# plt.xlabel('Batch #')\n","# plt.ylabel('CE/token')"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fnrdwwj6H-33"},"source":["# Tradução"]},{"cell_type":"markdown","metadata":{"id":"T1ZqWRcULu6u"},"source":["### Criando a classe do Tradutor"]},{"cell_type":"code","metadata":{"id":"GHPhEqAlIFZN","executionInfo":{"status":"ok","timestamp":1633566117235,"user_tz":180,"elapsed":279,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["#classe do Tradutor\n","class Translator(tf.Module):\n","\n","  def __init__(self, encoder, decoder, input_text_processor,\n","               output_text_processor):\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.input_text_processor = input_text_processor\n","    self.output_text_processor = output_text_processor\n","\n","    self.output_token_string_from_index = (\n","        tf.keras.layers.experimental.preprocessing.StringLookup(\n","            vocabulary=output_text_processor.get_vocabulary(),\n","            mask_token='',\n","            invert=True))\n","\n","    # The output should never generate padding, unknown, or start.\n","    index_from_string = tf.keras.layers.experimental.preprocessing.StringLookup(\n","        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n","    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n","\n","    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n","    token_mask[np.array(token_mask_ids)] = True\n","    self.token_mask = token_mask\n","\n","    self.start_token = index_from_string(tf.constant('[START]'))\n","    self.end_token = index_from_string(tf.constant('[END]'))"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"ExhKu8c2F1tG","executionInfo":{"status":"ok","timestamp":1633566604067,"user_tz":180,"elapsed":286,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["#instanciando o tradutor\n","translator = Translator(\n","    encoder=train_translator.encoder,\n","    decoder=train_translator.decoder,\n","    input_text_processor=input_text_processor,\n","    output_text_processor=output_text_processor,\n",")"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"64xooiuzI45d"},"source":["### Método para converter o texto em tokens"]},{"cell_type":"code","metadata":{"id":"K4Uq_mUpIY3z","executionInfo":{"status":"ok","timestamp":1633566607667,"user_tz":180,"elapsed":209,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["def tokens_to_text(self, result_tokens):\n","  shape_checker = ShapeChecker()\n","  shape_checker(result_tokens, ('batch', 't'))\n","  result_text_tokens = self.output_token_string_from_index(result_tokens)\n","  shape_checker(result_text_tokens, ('batch', 't'))\n","\n","  result_text = tf.strings.reduce_join(result_text_tokens,\n","                                       axis=1, separator=' ')\n","  shape_checker(result_text, ('batch'))\n","\n","  result_text = tf.strings.strip(result_text)\n","  shape_checker(result_text, ('batch',))\n","  return result_text\n","\n","Translator.tokens_to_text = tokens_to_text"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0uYQW0LOJELX","executionInfo":{"status":"ok","timestamp":1633566622855,"user_tz":180,"elapsed":249,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"54c18cc3-4268-47f9-fd5f-4a4c0db70ec4"},"source":["# testando\n","\n","example_output_tokens = tf.random.uniform(\n","    shape=[5, 2], minval=0, dtype=tf.int64,\n","    maxval=output_text_processor.vocabulary_size())\n","translator.tokens_to_text(example_output_tokens).numpy()"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'teaching divided', b'supplied reduce', b'coming jail',\n","       b'picasso gloomy', b'amused lot'], dtype=object)"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"fHjXWnovJT0a"},"source":["### Método para pegar as previsões"]},{"cell_type":"code","metadata":{"id":"5vllCZBVJeuF","executionInfo":{"status":"ok","timestamp":1633566629815,"user_tz":180,"elapsed":223,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["def sample(self, logits, temperature):\n","  shape_checker = ShapeChecker()\n","  # 't' is usually 1 here.\n","  shape_checker(logits, ('batch', 't', 'vocab'))\n","  shape_checker(self.token_mask, ('vocab',))\n","\n","  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n","  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n","\n","  # Set the logits for all masked tokens to -inf, so they are never chosen.\n","  logits = tf.where(self.token_mask, -np.inf, logits)\n","\n","  if temperature == 0.0:\n","    new_tokens = tf.argmax(logits, axis=-1)\n","  else: \n","    logits = tf.squeeze(logits, axis=1)\n","    new_tokens = tf.random.categorical(logits/temperature,\n","                                        num_samples=1)\n","  \n","  shape_checker(new_tokens, ('batch', 't'))\n","\n","  return new_tokens\n","\n","Translator.sample = sample"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S4rpcIuiJknX","executionInfo":{"status":"ok","timestamp":1633566643341,"user_tz":180,"elapsed":280,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"b810125b-b784-4159-ae7f-20d7fcd3eee3"},"source":["#Testando\n","example_logits = tf.random.normal([5, 1, output_text_processor.vocabulary_size()])\n","example_output_tokens = translator.sample(example_logits, temperature=1.0)\n","example_output_tokens"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n","array([[2566],\n","       [3885],\n","       [2745],\n","       [2910],\n","       [1426]])>"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"KIcp0t2oJ0jY"},"source":["### Método para executar o fluxo de tradução"]},{"cell_type":"code","metadata":{"id":"2eO7SHTHJwUY","executionInfo":{"status":"ok","timestamp":1633566666762,"user_tz":180,"elapsed":247,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["def translate_unrolled(self,\n","                       input_text, *,\n","                       max_length=50,\n","                       return_attention=True,\n","                       temperature=1.0):\n","  batch_size = tf.shape(input_text)[0]\n","  input_tokens = self.input_text_processor(input_text)\n","  enc_output, enc_state = self.encoder(input_tokens)\n","\n","  dec_state = enc_state\n","  new_tokens = tf.fill([batch_size, 1], self.start_token)\n","\n","  result_tokens = []\n","  attention = []\n","  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n","\n","  for _ in range(max_length):\n","    dec_input = DecoderInput(new_tokens=new_tokens,\n","                             enc_output=enc_output,\n","                             mask=(input_tokens!=0))\n","    \n","    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n","\n","    attention.append(dec_result.attention_weights)\n","\n","    new_tokens = self.sample(dec_result.logits, temperature)\n","\n","    # If a sequence produces an `end_token`, set it `done`\n","    done = done | (new_tokens == self.end_token)\n","    # Once a sequence is done it only produces 0-padding.\n","    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n","\n","    # Collect the generated tokens\n","    result_tokens.append(new_tokens)\n","\n","    if tf.executing_eagerly() and tf.reduce_all(done):\n","      break\n","\n","  # Convert the list of generates token ids to a list of strings.\n","  result_tokens = tf.concat(result_tokens, axis=-1)\n","  result_text = self.tokens_to_text(result_tokens)\n","\n","  if return_attention:\n","    attention_stack = tf.concat(attention, axis=1)\n","    return {'text': result_text, 'attention': attention_stack}\n","  else:\n","    return {'text': result_text}\n"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"_owhS3WqQBt_","executionInfo":{"status":"ok","timestamp":1633568175692,"user_tz":180,"elapsed":261,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}}},"source":["Translator.translate = translate_unrolled"],"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wq0pKyn6NbHl"},"source":["### Traduzindo"]},{"cell_type":"code","metadata":{"id":"dVjq1aK_MSn3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633566687086,"user_tz":180,"elapsed":712,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"2a300006-1eaa-4c28-9703-2198fad615d7"},"source":["%%time\n","input_text = tf.constant([\n","    'hace mucho frio aqui.', # \"It's really cold here.\"\n","    'Esta es mi vida.', # \"This is my life.\"\"\n","])\n","\n","result = translator.translate(\n","    input_text = input_text)\n","\n","print(result['text'][0].numpy().decode())\n","print(result['text'][1].numpy().decode())\n","print()"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["this is very cold in here .\n","this is my enemy .\n","\n","CPU times: user 367 ms, sys: 5.46 ms, total: 373 ms\n","Wall time: 372 ms\n"]}]},{"cell_type":"code","metadata":{"id":"R-BtNCY0Ndbg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633568179610,"user_tz":180,"elapsed":528,"user":{"displayName":"Ricardo Sousa","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhSj98soPmCDfxJ8iXam29UbqylSAwG4fUrqS1ctQ=s64","userId":"08277351312382030964"}},"outputId":"caa92a5f-8d4b-49c4-fb90-d5c022feb8b2"},"source":["# translator.translate(input_text = input_text)['text'][0].numpy().decode()\n","\n","print(f'Frases de teste: {example_input_batch[1]} {example_input_batch[8]}')\n","print(f'\\nResultado esperado: {example_target_batch[1]} {example_target_batch[8]}')\n","\n","input_text = tf.constant(['Ahora un computador es una absoluta necesidad.', 'No creo que su historia sea cierta'])\n","\n","test = translator.translate(input_text = input_text)\n","print('\\nPrimeira frase traduzida: {}'.format(test['text'][0].numpy().decode()))\n","print('Segunda frase traduzida: {}'.format(test['text'][1].numpy().decode()))"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Frases de teste: b'Ahora un computador es una absoluta necesidad.' b'No creo que su historia sea cierta.'\n","\n","Resultado esperado: b'A computer is an absolute necessity now.' b\"I don't think her story is true.\"\n","\n","Primeira frase traduzida: the a computer now is a painful lawyer .\n","Segunda frase traduzida: i dont believe his story is true .\n"]}]},{"cell_type":"code","metadata":{"id":"EIjreZPfMBfT"},"source":[""],"execution_count":null,"outputs":[]}]}